{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Features, Value, load_from_disk\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (MistralForCausalLM, MistralModel, MistralConfig, AutoModelForCasualLM, AutoTokenizer,\n\u001b[1;32m      7\u001b[0m                            AutoModelForMas, set_seed, Trainer, TrainingArguments, DataCollector, DataCollatorForLanguageModeling, DataCollatorForMas, HfArgumentParser, default_data_collator, \n\u001b[1;32m      8\u001b[0m                           EvalPrediction, PreTrainedTokenizer, PreTrainedModel, TrainingArguments, Trainer)\n",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01margparse\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Features, Value, load_from_disk\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (MistralForCausalLM, MistralModel, MistralConfig, AutoModelForCasualLM, AutoTokenizer,\n\u001b[1;32m      7\u001b[0m                            AutoModelForMas, set_seed, Trainer, TrainingArguments, DataCollector, DataCollatorForLanguageModeling, DataCollatorForMas, HfArgumentParser, default_data_collator, \n\u001b[1;32m      8\u001b[0m                           EvalPrediction, PreTrainedTokenizer, PreTrainedModel, TrainingArguments, Trainer)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os \n",
    "import argparse \n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset, Features, Value, load_from_disk\n",
    "from transformers import (MistralForCausalLM, MistralModel, MistralConfig, AutoModelForCasualLM, AutoTokenizer,\n",
    "                           AutoModelForMas, set_seed, Trainer, TrainingArguments, DataCollector, DataCollatorForLanguageModeling, DataCollatorForMas, HfArgumentParser, default_data_collator, \n",
    "               dsa           EvalPrediction, PreTrainedTokenizer, PreTrainedModel, TrainingArguments, Trainer)\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training, Aut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5903\n",
      "5903\n"
     ]
    }
   ],
   "source": [
    "# library to read .json files\n",
    "import json\n",
    "\n",
    "# read output-max.json file\n",
    "with open('./datasets/output-max-2.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "# remove from lsit\n",
    "def remove_from_list(x, list):\n",
    "    for i in list:\n",
    "        if i['title'] == x:\n",
    "            list.remove(i)\n",
    "    return list\n",
    "\n",
    "# remove from list titles with .jpg\n",
    "def remove_from_list_jpg(list):\n",
    "    for i in list:\n",
    "        if \".jpg\" in i['title']:\n",
    "            list.remove(i)\n",
    "    return list\n",
    "\n",
    "# remove titles with \"X\" \n",
    "data = remove_from_list(\"X\",data)\n",
    "\n",
    "# remove titles with \"Facebook\"\n",
    "data = remove_from_list(\"Facebook\",data)\n",
    "\n",
    "# remove titles with .jpg\n",
    "data = remove_from_list_jpg(data)\n",
    "\n",
    "print(len(data))\n",
    "\n",
    "# save to new json file with proper format\n",
    "with open('./datasets/output-max-cleaned.json', 'w') as f:\n",
    "    json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home\n",
      "  »  \n",
      "INFORMATION SYSTEMS\n",
      "  »   STUDENT ACADEMIC INFORMATION SYSTEM (SAIS)\n",
      "STUDENT ACADEMIC INFORMATION SYSTEM (SAIS)\n",
      "April 8, 2017 | Written by UP Media and Public Relations Office\n",
      "\n",
      "\n",
      "\n",
      "SAIS is a Student Lifecycle data management system encompassing admission application to graduation and alumni tracking. It covers curriculum, advisement, payment, and integration with general ledger in FMIS and employee records in HRIS.   |   LOGIN\n",
      "\n",
      " \n",
      "\n",
      "Comprehensive management of student records, including academic and financial data, throughout the complete student life cycle from admission to graduation.\n",
      "Comprehensive management of academic master data such as curricula and course information including pre-requisites.\n",
      "Comprehensive management of campus community data including student, faculty and alumni data.\n",
      "Integration with other systems including HRIS, FMIS, iLib, UPCAT, ST, Learning Management Systems, etc.\n",
      "Ability to manage student applications and admissions (non-UPCAT).\n",
      "Ability to manage financial aid and scholarships.\n",
      "Ability to generate Academic Advisement reports such as course checklists, study plans, etc.\n",
      "Ability to manage communications with students, faculty, and alumni. Alumni tracking.\n",
      "Online processes such as application for graduation, application for leave of absence, etc.\n",
      "Comprehensive student financial records, including detailed calculation of tuition and other fees, payment history, loan balances, refunds, etc.\n",
      "Pre-requisite checking\n",
      "Evaluation of requirements for graduation.\n",
      "Integration among UP CUs, and the ability to manage access to data. For example, registrar in one CU will be able to view the records of a student in another CU if given the authority to do so.\n",
      "Waiting lists for full classes, eliminating the need to physically wait in line for slots.\n",
      "Generation of course demand data, which can be used in determining class offerings.\n",
      "Ability to produce timely and accurate consolidated reports for the university, as well as reports organized by CU, College, office, etc. Reports will be easily accessible by authorized personnel.\n",
      "Communication tools – sending emails to groups, sending notifications and alerts, etc.\n",
      "Tagging of scholastic delinquencies, eligibility to enroll, etc.\n",
      "Integration with FMIS and HRIS\n",
      "Share this:\n"
     ]
    }
   ],
   "source": [
    "# library to read .json files\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# read output-max.json file\n",
    "with open('./datasets/output-max-cleaned.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# convert json to dataframe\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# clean html, only leave meaningful paragraphs\n",
    "s_text = df[\"html\"][24]\n",
    "# remove webcrawled html tags\n",
    "import re\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove html tags and href links from a string\"\"\"\n",
    "    clean_html = re.compile('<.*?>')\n",
    "    clean_href = re.compile(r'href=[\\'\"]?([^\\'\" >]+)')\n",
    "    text = re.sub(clean_html, '', text)\n",
    "    return re.sub(clean_href, '', text)\n",
    "\n",
    "\n",
    "# remove the last 32 lines of the html\n",
    "def remove_last_lines(text):\n",
    "    \"\"\"Remove the last 32 lines of the html\"\"\"\n",
    "    lines = text.splitlines()\n",
    "    lines = lines[:-32]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def remove_first_lines(text):\n",
    "    \"\"\"Remove the first  lines of the html\"\"\"\n",
    "    lines = text.splitlines()\n",
    "    lines = lines[6:]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean the text\"\"\"\n",
    "    text = remove_first_lines(text)\n",
    "    text = remove_last_lines(text)\n",
    "    text = remove_html_tags(text)\n",
    "    return text\n",
    "\n",
    "# test if data is cleaned\n",
    "# s_text = clean_text(s_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_course3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
